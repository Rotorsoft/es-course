// src/ports.ts
import { pino } from "pino";

// src/types/errors.ts
var Errors = {
  ValidationError: "ERR_VALIDATION",
  InvariantError: "ERR_INVARIANT",
  ConcurrencyError: "ERR_CONCURRENCY"
};
var ValidationError = class extends Error {
  constructor(target, payload, details) {
    super(`Invalid ${target} payload`);
    this.target = target;
    this.payload = payload;
    this.details = details;
    this.name = Errors.ValidationError;
  }
};
var InvariantError = class extends Error {
  constructor(action2, payload, target, snapshot, description) {
    super(`${action2} failed invariant: ${description}`);
    this.action = action2;
    this.payload = payload;
    this.target = target;
    this.snapshot = snapshot;
    this.description = description;
    this.name = Errors.InvariantError;
  }
};
var ConcurrencyError = class extends Error {
  constructor(stream, lastVersion, events, expectedVersion) {
    super(
      `Concurrency error committing "${events.map((e) => `${stream}.${e.name}.${JSON.stringify(e.data)}`).join(
        ", "
      )}". Expected version ${expectedVersion} but found version ${lastVersion}.`
    );
    this.stream = stream;
    this.lastVersion = lastVersion;
    this.events = events;
    this.expectedVersion = expectedVersion;
    this.name = Errors.ConcurrencyError;
  }
};

// src/utils.ts
import { prettifyError } from "zod";

// src/config.ts
import * as fs from "fs";
import { z as z2 } from "zod";

// src/types/schemas.ts
import { z } from "zod";
var ZodEmpty = z.record(z.string(), z.never());
var ActorSchema = z.object({
  id: z.string(),
  name: z.string()
}).readonly();
var TargetSchema = z.object({
  stream: z.string(),
  actor: ActorSchema,
  expectedVersion: z.number().optional()
}).readonly();
var CausationEventSchema = z.object({
  id: z.number(),
  name: z.string(),
  stream: z.string()
});
var EventMetaSchema = z.object({
  correlation: z.string(),
  causation: z.object({
    action: TargetSchema.and(z.object({ name: z.string() })).optional(),
    event: CausationEventSchema.optional()
  })
}).readonly();
var CommittedMetaSchema = z.object({
  id: z.number(),
  stream: z.string(),
  version: z.number(),
  created: z.date(),
  meta: EventMetaSchema
}).readonly();
var QuerySchema = z.object({
  stream: z.string().optional(),
  names: z.string().array().optional(),
  before: z.number().optional(),
  after: z.number().optional(),
  limit: z.number().optional(),
  created_before: z.date().optional(),
  created_after: z.date().optional(),
  backward: z.boolean().optional(),
  correlation: z.string().optional(),
  with_snaps: z.boolean().optional()
}).readonly();

// src/types/index.ts
var Environments = [
  "development",
  "test",
  "staging",
  "production"
];
var LogLevels = [
  "fatal",
  "error",
  "warn",
  "info",
  "debug",
  "trace"
];

// src/config.ts
var PackageSchema = z2.object({
  name: z2.string().min(1),
  version: z2.string().min(1),
  description: z2.string().min(1).optional(),
  author: z2.object({ name: z2.string().min(1), email: z2.string().optional() }).optional().or(z2.string().min(1)).optional(),
  license: z2.string().min(1).optional(),
  dependencies: z2.record(z2.string(), z2.string()).optional()
});
var getPackage = () => {
  const pkg2 = fs.readFileSync("package.json");
  return JSON.parse(pkg2.toString());
};
var BaseSchema = PackageSchema.extend({
  env: z2.enum(Environments),
  logLevel: z2.enum(LogLevels),
  logSingleLine: z2.boolean(),
  sleepMs: z2.number().int().min(0).max(5e3)
});
var { NODE_ENV, LOG_LEVEL, LOG_SINGLE_LINE, SLEEP_MS } = process.env;
var env = NODE_ENV || "development";
var logLevel = LOG_LEVEL || (NODE_ENV === "test" ? "error" : NODE_ENV === "production" ? "info" : "trace");
var logSingleLine = (LOG_SINGLE_LINE || "true") === "true";
var sleepMs = parseInt(NODE_ENV === "test" ? "0" : SLEEP_MS ?? "100");
var pkg = getPackage();
var config = () => {
  return extend({ ...pkg, env, logLevel, logSingleLine, sleepMs }, BaseSchema);
};

// src/utils.ts
var UNMERGEABLES = [
  RegExp,
  Date,
  Array,
  Map,
  Set,
  WeakMap,
  WeakSet,
  ArrayBuffer,
  SharedArrayBuffer,
  DataView,
  Int8Array,
  Uint8Array,
  Uint8ClampedArray,
  Int16Array,
  Uint16Array,
  Int32Array,
  Uint32Array,
  Float32Array,
  Float64Array
];
var is_mergeable = (value) => !!value && typeof value === "object" && !UNMERGEABLES.some((t) => value instanceof t);
var patch = (original, patches) => {
  const copy = {};
  Object.keys({ ...original, ...patches }).forEach((key) => {
    const patched_value = patches[key];
    const original_value = original[key];
    const patched = patches && key in patches;
    const deleted = patched && (typeof patched_value === "undefined" || patched_value === null);
    const value = patched && !deleted ? patched_value : original_value;
    !deleted && (copy[key] = is_mergeable(value) ? patch(original_value || {}, patched_value || {}) : value);
  });
  return copy;
};
var validate = (target, payload, schema) => {
  try {
    return schema ? schema.parse(payload) : payload;
  } catch (error) {
    if (error instanceof Error && error.name === "ZodError") {
      throw new ValidationError(
        target,
        payload,
        prettifyError(error)
      );
    }
    throw new ValidationError(target, payload, error);
  }
};
var extend = (source, schema, target) => {
  const value = validate("config", source, schema);
  return Object.assign(target || {}, value);
};
async function sleep(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms ?? config().sleepMs));
}

// src/adapters/InMemoryStore.ts
var InMemoryStream = class {
  constructor(stream, source) {
    this.stream = stream;
    this.source = source;
  }
  _at = -1;
  _retry = -1;
  _blocked = false;
  _error = "";
  _leased_by = void 0;
  _leased_until = void 0;
  get is_avaliable() {
    return !this._blocked && (!this._leased_until || this._leased_until <= /* @__PURE__ */ new Date());
  }
  get at() {
    return this._at;
  }
  /**
   * Attempt to lease this stream for processing.
   * @param lease - The lease request.
   * @param millis - Lease duration in milliseconds.
   * @returns The granted lease or undefined if blocked.
   */
  lease(lease, millis) {
    if (this.is_avaliable) {
      if (millis > 0) {
        this._leased_by = lease.by;
        this._leased_until = new Date(Date.now() + millis);
        this._retry = this._retry + 1;
      }
      return {
        stream: this.stream,
        source: this.source,
        at: lease.at,
        by: lease.by,
        retry: this._retry,
        lagging: lease.lagging
      };
    }
  }
  /**
   * Acknowledge completion of processing for this stream.
   * @param lease - The lease request.
   */
  ack(lease) {
    if (this._leased_by === lease.by) {
      this._leased_by = void 0;
      this._leased_until = void 0;
      this._at = lease.at;
      this._retry = -1;
      return {
        stream: this.stream,
        source: this.source,
        at: this._at,
        by: lease.by,
        retry: this._retry,
        lagging: lease.lagging
      };
    }
  }
  /**
   * Block a stream for processing after failing to process and reaching max retries with blocking enabled.
   * @param lease - The lease request.
   * @param error Blocked error message.
   */
  block(lease, error) {
    if (this._leased_by === lease.by) {
      this._blocked = true;
      this._error = error;
      return {
        stream: this.stream,
        source: this.source,
        at: this._at,
        by: this._leased_by,
        retry: this._retry,
        error: this._error,
        lagging: lease.lagging
      };
    }
  }
};
var InMemoryStore = class {
  // stored events
  _events = [];
  // stored stream positions and other metadata
  _streams = /* @__PURE__ */ new Map();
  /**
   * Dispose of the store and clear all events.
   * @returns Promise that resolves when disposal is complete.
   */
  async dispose() {
    await sleep();
    this._events.length = 0;
  }
  /**
   * Seed the store with initial data (no-op for in-memory).
   * @returns Promise that resolves when seeding is complete.
   */
  async seed() {
    await sleep();
  }
  /**
   * Drop all data from the store.
   * @returns Promise that resolves when the store is cleared.
   */
  async drop() {
    await sleep();
    this._events.length = 0;
    this._streams = /* @__PURE__ */ new Map();
  }
  in_query(query, e) {
    if (query.stream && !RegExp(`^${query.stream}$`).test(e.stream))
      return false;
    if (query.names && !query.names.includes(e.name)) return false;
    if (query.correlation && e.meta?.correlation !== query.correlation)
      return false;
    if (e.name === SNAP_EVENT && !query.with_snaps) return false;
    return true;
  }
  /**
   * Query events in the store, optionally filtered by query options.
   * @param callback - Function to call for each event.
   * @param query - Optional query options.
   * @returns The number of events processed.
   */
  async query(callback, query) {
    await sleep();
    let count = 0;
    if (query?.backward) {
      let i = (query?.before || this._events.length) - 1;
      while (i >= 0) {
        const e = this._events[i--];
        if (query && !this.in_query(query, e)) continue;
        if (query?.created_before && e.created >= query.created_before)
          continue;
        if (query.after && e.id <= query.after) break;
        if (query.created_after && e.created <= query.created_after) break;
        callback(e);
        count++;
        if (query?.limit && count >= query.limit) break;
      }
    } else {
      let i = (query?.after ?? -1) + 1;
      while (i < this._events.length) {
        const e = this._events[i++];
        if (query && !this.in_query(query, e)) continue;
        if (query?.created_after && e.created <= query.created_after) continue;
        if (query?.before && e.id >= query.before) break;
        if (query?.created_before && e.created >= query.created_before) break;
        callback(e);
        count++;
        if (query?.limit && count >= query.limit) break;
      }
    }
    return count;
  }
  /**
   * Commit one or more events to a stream.
   * @param stream - The stream name.
   * @param msgs - The events/messages to commit.
   * @param meta - Event metadata.
   * @param expectedVersion - Optional optimistic concurrency check.
   * @returns The committed events with metadata.
   * @throws ConcurrencyError if expectedVersion does not match.
   */
  async commit(stream, msgs, meta, expectedVersion) {
    await sleep();
    const instance = this._events.filter((e) => e.stream === stream);
    if (typeof expectedVersion === "number" && instance.length - 1 !== expectedVersion) {
      throw new ConcurrencyError(
        stream,
        instance.length - 1,
        msgs,
        expectedVersion
      );
    }
    let version = instance.length;
    return msgs.map(({ name, data }) => {
      const committed = {
        id: this._events.length,
        stream,
        version,
        created: /* @__PURE__ */ new Date(),
        name,
        data,
        meta
      };
      this._events.push(committed);
      version++;
      return committed;
    });
  }
  /**
   * Polls the store for unblocked streams needing processing, ordered by lease watermark ascending.
   * @param lagging - Max number of streams to poll in ascending order.
   * @param leading - Max number of streams to poll in descending order.
   * @returns The polled streams.
   */
  async poll(lagging, leading) {
    await sleep();
    const a = [...this._streams.values()].filter((s) => s.is_avaliable).sort((a2, b2) => a2.at - b2.at).slice(0, lagging).map(({ stream, source, at }) => ({
      stream,
      source,
      at,
      lagging: true
    }));
    const b = [...this._streams.values()].filter((s) => s.is_avaliable).sort((a2, b2) => b2.at - a2.at).slice(0, leading).map(({ stream, source, at }) => ({
      stream,
      source,
      at,
      lagging: false
    }));
    return [...a, ...b];
  }
  /**
   * Lease streams for processing (e.g., for distributed consumers).
   * @param leases - Lease requests for streams, including end-of-lease watermark, lease holder, and source stream.
   * @param leaseMilis - Lease duration in milliseconds.
   * @returns Granted leases.
   */
  async lease(leases, millis) {
    await sleep();
    return leases.map((l) => {
      if (!this._streams.has(l.stream)) {
        this._streams.set(l.stream, new InMemoryStream(l.stream, l.source));
      }
      return this._streams.get(l.stream)?.lease(l, millis);
    }).filter((l) => !!l);
  }
  /**
   * Acknowledge completion of processing for leased streams.
   * @param leases - Leases to acknowledge, including last processed watermark and lease holder.
   */
  async ack(leases) {
    await sleep();
    return leases.map((l) => this._streams.get(l.stream)?.ack(l)).filter((l) => !!l);
  }
  /**
   * Block a stream for processing after failing to process and reaching max retries with blocking enabled.
   * @param leases - Leases to block, including lease holder and last error message.
   * @returns Blocked leases.
   */
  async block(leases) {
    await sleep();
    return leases.map((l) => this._streams.get(l.stream)?.block(l, l.error)).filter((l) => !!l);
  }
};

// src/ports.ts
var ExitCodes = ["ERROR", "EXIT"];
var logger = pino({
  transport: config().env !== "production" ? {
    target: "pino-pretty",
    options: {
      ignore: "pid,hostname",
      singleLine: config().logSingleLine,
      colorize: true
    }
  } : void 0,
  level: config().logLevel
});
var adapters = /* @__PURE__ */ new Map();
function port(injector) {
  return function(adapter) {
    if (!adapters.has(injector.name)) {
      const injected = injector(adapter);
      adapters.set(injector.name, injected);
      logger.info(`\u{1F50C} injected ${injector.name}:${injected.constructor.name}`);
    }
    return adapters.get(injector.name);
  };
}
var disposers = [];
async function disposeAndExit(code = "EXIT") {
  if (code === "ERROR" && config().env === "production") return;
  await Promise.all(disposers.map((disposer) => disposer()));
  await Promise.all(
    [...adapters.values()].reverse().map(async (adapter) => {
      await adapter.dispose();
      logger.info(`\u{1F50C} disposed ${adapter.constructor.name}`);
    })
  );
  adapters.clear();
  config().env !== "test" && process.exit(code === "ERROR" ? 1 : 0);
}
function dispose(disposer) {
  disposer && disposers.push(disposer);
  return disposeAndExit;
}
var SNAP_EVENT = "__snapshot__";
var store = port(function store2(adapter) {
  return adapter || new InMemoryStore();
});
function build_tracer(logLevel2) {
  if (logLevel2 === "trace") {
    return {
      fetched: (fetched) => {
        const data = Object.fromEntries(
          fetched.map(({ stream, source, events }) => {
            const key = source ? `${stream}<-${source}` : stream;
            const value = Object.fromEntries(
              events.map(({ id, stream: stream2, name }) => [id, { [stream2]: name }])
            );
            return [key, value];
          })
        );
        logger.trace(data, "\u26A1\uFE0F fetch");
      },
      correlated: (leases) => {
        const data = leases.map(({ stream }) => stream).join(" ");
        logger.trace(`\u26A1\uFE0F correlate ${data}`);
      },
      leased: (leases) => {
        const data = Object.fromEntries(
          leases.map(({ stream, at, retry }) => [stream, { at, retry }])
        );
        logger.trace(data, "\u26A1\uFE0F lease");
      },
      acked: (leases) => {
        const data = Object.fromEntries(
          leases.map(({ stream, at, retry }) => [stream, { at, retry }])
        );
        logger.trace(data, "\u26A1\uFE0F ack");
      },
      blocked: (leases) => {
        const data = Object.fromEntries(
          leases.map(({ stream, at, retry, error }) => [
            stream,
            { at, retry, error }
          ])
        );
        logger.trace(data, "\u26A1\uFE0F block");
      }
    };
  } else {
    return {
      fetched: () => {
      },
      correlated: () => {
      },
      leased: () => {
      },
      acked: () => {
      },
      blocked: () => {
      }
    };
  }
}

// src/signals.ts
process.once("SIGINT", async (arg) => {
  logger.info(arg, "SIGINT");
  await disposeAndExit("EXIT");
});
process.once("SIGTERM", async (arg) => {
  logger.info(arg, "SIGTERM");
  await disposeAndExit("EXIT");
});
process.once("uncaughtException", async (arg) => {
  logger.error(arg, "Uncaught Exception");
  await disposeAndExit("ERROR");
});
process.once("unhandledRejection", async (arg) => {
  logger.error(arg, "Unhandled Rejection");
  await disposeAndExit("ERROR");
});

// src/act.ts
import { randomUUID as randomUUID2 } from "crypto";
import EventEmitter from "events";

// src/event-sourcing.ts
import { randomUUID } from "crypto";
async function snap(snapshot) {
  try {
    const { id, stream, name, meta, version } = snapshot.event;
    const snapped = await store().commit(
      stream,
      [{ name: SNAP_EVENT, data: snapshot.state }],
      {
        correlation: meta.correlation,
        causation: { event: { id, name, stream } }
      },
      version
      // IMPORTANT! - state events are committed right after the snapshot event
    );
    logger.trace(snapped, "\u{1F7E0} snap");
  } catch (error) {
    logger.error(error);
  }
}
async function load(me, stream, callback) {
  let state2 = me.init ? me.init() : {};
  let patches = 0;
  let snaps = 0;
  let event;
  await store().query(
    (e) => {
      event = e;
      if (e.name === SNAP_EVENT) {
        state2 = e.data;
        snaps++;
        patches = 0;
      } else if (me.patch[e.name]) {
        state2 = patch(state2, me.patch[e.name](event, state2));
        patches++;
      }
      callback && callback({ event, state: state2, patches, snaps });
    },
    { stream, with_snaps: true }
  );
  logger.trace(state2, `\u{1F7E2} load ${stream}`);
  return { event, state: state2, patches, snaps };
}
async function action(me, action2, target, payload, reactingTo, skipValidation = false) {
  const { stream, expectedVersion, actor } = target;
  if (!stream) throw new Error("Missing target stream");
  payload = skipValidation ? payload : validate(action2, payload, me.actions[action2]);
  const snapshot = await load(me, stream);
  const expected = expectedVersion || snapshot.event?.version;
  logger.trace(
    payload,
    `\u{1F535} ${stream}.${action2}${typeof expected === "number" ? `.${expected}` : ""}`
  );
  if (me.given) {
    const invariants = me.given[action2] || [];
    invariants.forEach(({ valid, description }) => {
      if (!valid(snapshot.state, actor))
        throw new InvariantError(
          action2,
          payload,
          target,
          snapshot,
          description
        );
    });
  }
  const result = me.on[action2](payload, snapshot, target);
  if (!result) return [snapshot];
  if (Array.isArray(result) && result.length === 0) {
    return [snapshot];
  }
  const tuples = Array.isArray(result[0]) ? result : [result];
  const emitted = tuples.map(([name, data]) => ({
    name,
    data: skipValidation ? data : validate(name, data, me.events[name])
  }));
  const meta = {
    correlation: reactingTo?.meta.correlation || randomUUID(),
    causation: {
      action: {
        name: action2,
        ...target
        // payload: TODO: flag to include action payload in metadata
        // not included by default to avoid large payloads
      },
      event: reactingTo ? {
        id: reactingTo.id,
        name: reactingTo.name,
        stream: reactingTo.stream
      } : void 0
    }
  };
  logger.trace(
    emitted.map((e) => e.data),
    `\u{1F534} commit ${stream}.${emitted.map((e) => e.name).join(", ")}`
  );
  const committed = await store().commit(
    stream,
    emitted,
    meta,
    // TODO: review reactions not enforcing expected version
    reactingTo ? void 0 : expected
  );
  let { state: state2, patches } = snapshot;
  const snapshots = committed.map((event) => {
    state2 = patch(state2, me.patch[event.name](event, state2));
    patches++;
    return { event, state: state2, patches, snaps: snapshot.snaps };
  });
  const last = snapshots.at(-1);
  me.snap && me.snap(last) && void snap(last);
  return snapshots;
}

// src/act.ts
var tracer = build_tracer(config().logLevel);
var Act = class {
  /**
   * Create a new Act orchestrator.
   *
   * @param registry The registry of state, event, and action schemas
   * @param states Map of state names to their (potentially merged) state definitions
   */
  constructor(registry, _states = /* @__PURE__ */ new Map()) {
    this.registry = registry;
    this._states = _states;
    dispose(() => {
      this._emitter.removeAllListeners();
      this.stop_correlations();
      return Promise.resolve();
    });
  }
  _emitter = new EventEmitter();
  _drain_locked = false;
  _drain_lag2lead_ratio = 0.5;
  _correlation_interval = void 0;
  emit(event, args) {
    return this._emitter.emit(event, args);
  }
  on(event, listener) {
    this._emitter.on(event, listener);
    return this;
  }
  off(event, listener) {
    this._emitter.off(event, listener);
    return this;
  }
  /**
   * Executes an action on a state instance, committing resulting events.
   *
   * This is the primary method for modifying state. It:
   * 1. Validates the action payload against the schema
   * 2. Loads the current state snapshot
   * 3. Checks invariants (business rules)
   * 4. Executes the action handler to generate events
   * 5. Applies events to create new state
   * 6. Commits events to the store with optimistic concurrency control
   *
   * @template K - Action name from registered actions
   * @param action - The name of the action to execute
   * @param target - Target specification with stream ID and actor context
   * @param payload - Action payload matching the action's schema
   * @param reactingTo - Optional event that triggered this action (for correlation)
   * @param skipValidation - Skip schema validation (use carefully, for performance)
   * @returns Array of snapshots for all affected states (usually one)
   *
   * @throws {ValidationError} If payload doesn't match action schema
   * @throws {InvariantError} If business rules are violated
   * @throws {ConcurrencyError} If another process modified the stream
   *
   * @example Basic action execution
   * ```typescript
   * const snapshots = await app.do(
   *   "increment",
   *   {
   *     stream: "counter-1",
   *     actor: { id: "user1", name: "Alice" }
   *   },
   *   { by: 5 }
   * );
   *
   * console.log(snapshots[0].state.count); // Current count after increment
   * ```
   *
   * @example With error handling
   * ```typescript
   * try {
   *   await app.do(
   *     "withdraw",
   *     { stream: "account-123", actor: { id: "user1", name: "Alice" } },
   *     { amount: 1000 }
   *   );
   * } catch (error) {
   *   if (error instanceof InvariantError) {
   *     console.error("Business rule violated:", error.description);
   *   } else if (error instanceof ConcurrencyError) {
   *     console.error("Concurrent modification detected, retry...");
   *   } else if (error instanceof ValidationError) {
   *     console.error("Invalid payload:", error.details);
   *   }
   * }
   * ```
   *
   * @example Reaction triggering another action
   * ```typescript
   * const app = act()
   *   .with(Order)
   *   .with(Inventory)
   *   .on("OrderPlaced")
   *     .do(async (event, context) => {
   *       // This action is triggered by an event
   *       const result = await context.app.do(
   *         "reduceStock",
   *         {
   *           stream: "inventory-1",
   *           actor: event.meta.causation.action.actor
   *         },
   *         { amount: event.data.items.length },
   *         event // Pass event for correlation tracking
   *       );
   *       return result;
   *     })
   *     .to("inventory-1")
   *   .build();
   * ```
   *
   * @see {@link Target} for target structure
   * @see {@link Snapshot} for return value structure
   * @see {@link ValidationError}, {@link InvariantError}, {@link ConcurrencyError}
   */
  async do(action2, target, payload, reactingTo, skipValidation = false) {
    const snapshots = await action(
      this.registry.actions[action2],
      action2,
      target,
      payload,
      reactingTo,
      skipValidation
    );
    this.emit("committed", snapshots);
    return snapshots;
  }
  async load(stateOrName, stream, callback) {
    let merged;
    if (typeof stateOrName === "string") {
      const found = this._states.get(stateOrName);
      if (!found) throw new Error(`State "${stateOrName}" not found`);
      merged = found;
    } else {
      merged = this._states.get(stateOrName.name) || stateOrName;
    }
    return await load(merged, stream, callback);
  }
  /**
   * Queries the event store for events matching a filter.
   *
   * Use this for analyzing event streams, generating reports, or debugging.
   * The callback is invoked for each matching event, and the method returns
   * summary information (first event, last event, total count).
   *
   * For small result sets, consider using {@link query_array} instead.
   *
   * @param query - The query filter
   * @param query.stream - Filter by stream ID
   * @param query.name - Filter by event name
   * @param query.after - Filter events after this event ID
   * @param query.before - Filter events before this event ID
   * @param query.created_after - Filter events after this timestamp
   * @param query.created_before - Filter events before this timestamp
   * @param query.limit - Maximum number of events to return
   * @param callback - Optional callback invoked for each matching event
   * @returns Object with first event, last event, and total count
   *
   * @example Query all events for a stream
   * ```typescript
   * const { first, last, count } = await app.query(
   *   { stream: "counter-1" },
   *   (event) => console.log(event.name, event.data)
   * );
   * console.log(`Found ${count} events from ${first?.id} to ${last?.id}`);
   * ```
   *
   * @example Query specific event types
   * ```typescript
   * const { count } = await app.query(
   *   { name: "UserCreated", limit: 100 },
   *   (event) => {
   *     console.log("User created:", event.data.email);
   *   }
   * );
   * ```
   *
   * @example Query events in time range
   * ```typescript
   * const yesterday = new Date(Date.now() - 24 * 60 * 60 * 1000);
   * const { count } = await app.query({
   *   created_after: yesterday,
   *   stream: "user-123"
   * });
   * console.log(`User had ${count} events in last 24 hours`);
   * ```
   *
   * @see {@link query_array} for loading events into memory
   */
  async query(query, callback) {
    let first = void 0, last = void 0;
    const count = await store().query((e) => {
      !first && (first = e);
      last = e;
      callback && callback(e);
    }, query);
    return { first, last, count };
  }
  /**
   * Queries the event store and returns all matching events in memory.
   *
   * **Use with caution** - this loads all results into memory. For large result sets,
   * use {@link query} with a callback instead to process events incrementally.
   *
   * @param query - The query filter (same as {@link query})
   * @returns Array of all matching events
   *
   * @example Load all events for a stream
   * ```typescript
   * const events = await app.query_array({ stream: "counter-1" });
   * console.log(`Loaded ${events.length} events`);
   * events.forEach(event => console.log(event.name, event.data));
   * ```
   *
   * @example Get recent events
   * ```typescript
   * const recent = await app.query_array({
   *   stream: "user-123",
   *   limit: 10
   * });
   * ```
   *
   * @see {@link query} for large result sets
   */
  async query_array(query) {
    const events = [];
    await store().query((e) => events.push(e), query);
    return events;
  }
  /**
   * Handles leased reactions.
   *
   * This is called by the main `drain` loop after fetching new events.
   * It handles reactions, supporting retries, blocking, and error handling.
   *
   * @internal
   * @param lease The lease to handle
   * @param payloads The reactions to handle
   * @returns The lease with results
   */
  async handle(lease, payloads) {
    if (payloads.length === 0) return { lease, handled: 0, at: lease.at };
    const stream = lease.stream;
    let at = payloads.at(0).event.id, handled = 0;
    lease.retry > 0 && logger.warn(`Retrying ${stream}@${at} (${lease.retry}).`);
    for (const payload of payloads) {
      const { event, handler, options } = payload;
      try {
        await handler(event, stream, this);
        at = event.id;
        handled++;
      } catch (error) {
        logger.error(error);
        const block = lease.retry >= options.maxRetries && options.blockOnError;
        block && logger.error(`Blocking ${stream} after ${lease.retry} retries.`);
        return {
          lease,
          handled,
          at,
          // only report error when nothing was handled
          error: handled === 0 ? error.message : void 0,
          block
        };
      }
    }
    return { lease, handled, at };
  }
  /**
   * Processes pending reactions by draining uncommitted events from the event store.
   *
   * The drain process:
   * 1. Polls the store for streams with uncommitted events
   * 2. Leases streams to prevent concurrent processing
   * 3. Fetches events for each leased stream
   * 4. Executes matching reaction handlers
   * 5. Acknowledges successful reactions or blocks failing ones
   *
   * Drain uses a dual-frontier strategy to balance processing of new streams (lagging)
   * vs active streams (leading). The ratio adapts based on event pressure.
   *
   * Call this method periodically in a background loop, or after committing events.
   *
   * @param options - Drain configuration options
   * @param options.streamLimit - Maximum number of streams to process per cycle (default: 10)
   * @param options.eventLimit - Maximum events to fetch per stream (default: 10)
   * @param options.leaseMillis - Lease duration in milliseconds (default: 10000)
   * @returns Drain statistics with fetched, leased, acked, and blocked counts
   *
   * @example Basic drain loop
   * ```typescript
   * // Process reactions after each action
   * await app.do("createUser", target, payload);
   * await app.drain();
   * ```
   *
   * @example Background drain worker
   * ```typescript
   * setInterval(async () => {
   *   try {
   *     const result = await app.drain({
   *       streamLimit: 20,
   *       eventLimit: 50
   *     });
   *     if (result.acked.length) {
   *       console.log(`Processed ${result.acked.length} streams`);
   *     }
   *   } catch (error) {
   *     console.error("Drain error:", error);
   *   }
   * }, 5000); // Every 5 seconds
   * ```
   *
   * @example With lifecycle listeners
   * ```typescript
   * app.on("acked", (leases) => {
   *   console.log(`Acknowledged ${leases.length} streams`);
   * });
   *
   * app.on("blocked", (blocked) => {
   *   console.error(`Blocked ${blocked.length} streams due to errors`);
   *   blocked.forEach(({ stream, error }) => {
   *     console.error(`Stream ${stream}: ${error}`);
   *   });
   * });
   *
   * await app.drain();
   * ```
   *
   * @see {@link correlate} for dynamic stream discovery
   * @see {@link start_correlations} for automatic correlation
   */
  async drain({
    streamLimit = 10,
    eventLimit = 10,
    leaseMillis = 1e4
  } = {}) {
    if (!this._drain_locked) {
      try {
        this._drain_locked = true;
        const lagging = Math.ceil(streamLimit * this._drain_lag2lead_ratio);
        const leading = streamLimit - lagging;
        const polled = await store().poll(lagging, leading);
        const fetched = await Promise.all(
          polled.map(async ({ stream, source, at, lagging: lagging2 }) => {
            const events = await this.query_array({
              stream: source,
              after: at,
              limit: eventLimit
            });
            return { stream, source, at, lagging: lagging2, events };
          })
        );
        if (fetched.length) {
          tracer.fetched(fetched);
          const leases = /* @__PURE__ */ new Map();
          const fetch_window_at = fetched.reduce(
            (max, { at, events }) => Math.max(max, events.at(-1)?.id || at),
            0
          );
          fetched.forEach(({ stream, lagging: lagging2, events }) => {
            const payloads = events.flatMap((event) => {
              const register = this.registry.events[event.name];
              if (!register) return [];
              return [...register.reactions.values()].filter((reaction) => {
                const resolved = typeof reaction.resolver === "function" ? reaction.resolver(event) : reaction.resolver;
                return resolved && resolved.target === stream;
              }).map((reaction) => ({ ...reaction, event }));
            });
            leases.set(stream, {
              lease: {
                stream,
                by: randomUUID2(),
                at: events.at(-1)?.id || fetch_window_at,
                // ff when no matching events
                retry: 0,
                lagging: lagging2
              },
              payloads
            });
          });
          const leased = await store().lease(
            [...leases.values()].map(({ lease }) => lease),
            leaseMillis
          );
          tracer.leased(leased);
          const handled = await Promise.all(
            leased.map(
              (lease) => this.handle(lease, leases.get(lease.stream).payloads)
            )
          );
          const [lagging_handled, leading_handled] = handled.reduce(
            ([lagging_handled2, leading_handled2], { lease, handled: handled2 }) => [
              lagging_handled2 + (lease.lagging ? handled2 : 0),
              leading_handled2 + (lease.lagging ? 0 : handled2)
            ],
            [0, 0]
          );
          const lagging_avg = lagging > 0 ? lagging_handled / lagging : 0;
          const leading_avg = leading > 0 ? leading_handled / leading : 0;
          const total = lagging_avg + leading_avg;
          this._drain_lag2lead_ratio = total > 0 ? Math.max(0.2, Math.min(0.8, lagging_avg / total)) : 0.5;
          const acked = await store().ack(
            handled.filter(({ error }) => !error).map(({ at, lease }) => ({ ...lease, at }))
          );
          if (acked.length) {
            tracer.acked(acked);
            this.emit("acked", acked);
          }
          const blocked = await store().block(
            handled.filter(({ block }) => block).map(({ lease, error }) => ({ ...lease, error }))
          );
          if (blocked.length) {
            tracer.blocked(blocked);
            this.emit("blocked", blocked);
          }
          return { fetched, leased, acked, blocked };
        }
      } catch (error) {
        logger.error(error);
      } finally {
        this._drain_locked = false;
      }
    }
    return { fetched: [], leased: [], acked: [], blocked: [] };
  }
  /**
   * Discovers and registers new streams dynamically based on reaction resolvers.
   *
   * Correlation enables "dynamic reactions" where target streams are determined at runtime
   * based on event content. For example, you might create a stats stream for each user
   * when they perform certain actions.
   *
   * This method scans events matching the query and identifies new target streams based
   * on reaction resolvers. It then registers these streams so they'll be picked up by
   * the next drain cycle.
   *
   * @param query - Query filter to scan for new correlations
   * @param query.after - Start scanning after this event ID (default: -1)
   * @param query.limit - Maximum events to scan (default: 10)
   * @returns Object with newly leased streams and last scanned event ID
   *
   * @example Manual correlation
   * ```typescript
   * // Scan for new streams
   * const { leased, last_id } = await app.correlate({ after: 0, limit: 100 });
   * console.log(`Found ${leased.length} new streams`);
   *
   * // Save last_id for next scan
   * await saveCheckpoint(last_id);
   * ```
   *
   * @example Dynamic stream creation
   * ```typescript
   * const app = act()
   *   .with(User)
   *   .with(UserStats)
   *   .on("UserLoggedIn")
   *     .do(async (event) => ["incrementLoginCount", {}])
   *     .to((event) => ({
   *       target: `stats-${event.stream}` // Dynamic target per user
   *     }))
   *   .build();
   *
   * // Discover stats streams as users log in
   * await app.correlate();
   * ```
   *
   * @see {@link start_correlations} for automatic periodic correlation
   * @see {@link stop_correlations} to stop automatic correlation
   */
  async correlate(query = { after: -1, limit: 10 }) {
    const correlated = /* @__PURE__ */ new Map();
    let last_id = query.after || -1;
    await store().query((event) => {
      last_id = event.id;
      const register = this.registry.events[event.name];
      if (register) {
        for (const reaction of register.reactions.values()) {
          const resolved = typeof reaction.resolver === "function" ? reaction.resolver(event) : reaction.resolver;
          resolved && (correlated.get(resolved.target) || correlated.set(resolved.target, []).get(resolved.target)).push({ ...reaction, source: resolved.source, event });
        }
      }
    }, query);
    if (correlated.size) {
      const leases = [...correlated.entries()].map(([stream, payloads]) => ({
        stream,
        // TODO: by convention, the first defined source wins (this can be tricky)
        source: payloads.find((p) => p.source)?.source || void 0,
        by: randomUUID2(),
        at: 0,
        retry: 0,
        lagging: true,
        payloads
      }));
      const leased = await store().lease(leases, 0);
      leased.length && tracer.correlated(leased);
      return { leased, last_id };
    }
    return { leased: [], last_id };
  }
  /**
   * Starts automatic periodic correlation worker for discovering new streams.
   *
   * The correlation worker runs in the background, scanning for new events and identifying
   * new target streams based on reaction resolvers. It maintains a sliding window that
   * advances with each scan, ensuring all events are eventually correlated.
   *
   * This is useful for dynamic stream creation patterns where you don't know all streams
   * upfront - they're discovered as events arrive.
   *
   * **Note:** Only one correlation worker can run at a time per Act instance.
   *
   * @param query - Query filter for correlation scans
   * @param query.after - Initial starting point (default: -1, start from beginning)
   * @param query.limit - Events to scan per cycle (default: 100)
   * @param frequency - Correlation frequency in milliseconds (default: 10000)
   * @param callback - Optional callback invoked with newly discovered streams
   * @returns `true` if worker started, `false` if already running
   *
   * @example Start automatic correlation
   * ```typescript
   * // Start correlation worker scanning every 5 seconds
   * app.start_correlations(
   *   { after: 0, limit: 100 },
   *   5000,
   *   (leased) => {
   *     console.log(`Discovered ${leased.length} new streams`);
   *   }
   * );
   *
   * // Later, stop it
   * app.stop_correlations();
   * ```
   *
   * @example With checkpoint persistence
   * ```typescript
   * // Load last checkpoint
   * const lastId = await loadCheckpoint();
   *
   * app.start_correlations(
   *   { after: lastId, limit: 100 },
   *   10000,
   *   async (leased) => {
   *     // Save checkpoint for next restart
   *     if (leased.length) {
   *       const maxId = Math.max(...leased.map(l => l.at));
   *       await saveCheckpoint(maxId);
   *     }
   *   }
   * );
   * ```
   *
   * @see {@link correlate} for manual one-time correlation
   * @see {@link stop_correlations} to stop the worker
   */
  start_correlations(query = {}, frequency = 1e4, callback) {
    if (this._correlation_interval) return false;
    const limit = query.limit || 100;
    let after = query.after || -1;
    this._correlation_interval = setInterval(
      () => this.correlate({ ...query, after, limit }).then((result) => {
        after = result.last_id;
        if (callback && result.leased.length) callback(result.leased);
      }).catch(console.error),
      frequency
    );
    return true;
  }
  /**
   * Stops the automatic correlation worker.
   *
   * Call this to stop the background correlation worker started by {@link start_correlations}.
   * This is automatically called when the Act instance is disposed.
   *
   * @example
   * ```typescript
   * // Start correlation
   * app.start_correlations();
   *
   * // Later, stop it
   * app.stop_correlations();
   * ```
   *
   * @see {@link start_correlations}
   */
  stop_correlations() {
    if (this._correlation_interval) {
      clearInterval(this._correlation_interval);
      this._correlation_interval = void 0;
    }
  }
};

// src/merge.ts
import { ZodObject as ZodObject2 } from "zod";
function baseTypeName(zodType) {
  let t = zodType;
  while (typeof t.unwrap === "function") {
    t = t.unwrap();
  }
  return t.constructor.name;
}
function mergeSchemas(existing, incoming, stateName) {
  if (existing instanceof ZodObject2 && incoming instanceof ZodObject2) {
    const existingShape = existing.shape;
    const incomingShape = incoming.shape;
    for (const key of Object.keys(incomingShape)) {
      if (key in existingShape) {
        const existingBase = baseTypeName(existingShape[key]);
        const incomingBase = baseTypeName(incomingShape[key]);
        if (existingBase !== incomingBase) {
          throw new Error(
            `Schema conflict in "${stateName}": key "${key}" has type "${existingBase}" but incoming partial declares "${incomingBase}"`
          );
        }
      }
    }
    return existing.extend(incomingShape);
  }
  return existing;
}
function mergeInits(existing, incoming) {
  return () => ({ ...existing(), ...incoming() });
}
function registerState(state2, states, actions, events) {
  if (states.has(state2.name)) {
    const existing = states.get(state2.name);
    for (const name of Object.keys(state2.actions)) {
      if (existing.actions[name] === state2.actions[name]) continue;
      if (actions[name]) throw new Error(`Duplicate action "${name}"`);
    }
    for (const name of Object.keys(state2.events)) {
      if (existing.events[name] === state2.events[name]) continue;
      if (events[name]) throw new Error(`Duplicate event "${name}"`);
    }
    const merged = {
      ...existing,
      state: mergeSchemas(existing.state, state2.state, state2.name),
      init: mergeInits(existing.init, state2.init),
      events: { ...existing.events, ...state2.events },
      actions: { ...existing.actions, ...state2.actions },
      patch: { ...existing.patch, ...state2.patch },
      on: { ...existing.on, ...state2.on },
      given: { ...existing.given, ...state2.given },
      snap: state2.snap || existing.snap
    };
    states.set(state2.name, merged);
    for (const name of Object.keys(merged.actions)) {
      actions[name] = merged;
    }
    for (const name of Object.keys(state2.events)) {
      if (events[name]) continue;
      events[name] = {
        schema: state2.events[name],
        reactions: /* @__PURE__ */ new Map()
      };
    }
  } else {
    states.set(state2.name, state2);
    for (const name of Object.keys(state2.actions)) {
      if (actions[name]) throw new Error(`Duplicate action "${name}"`);
      actions[name] = state2;
    }
    for (const name of Object.keys(state2.events)) {
      if (events[name]) throw new Error(`Duplicate event "${name}"`);
      events[name] = {
        schema: state2.events[name],
        reactions: /* @__PURE__ */ new Map()
      };
    }
  }
}
var _this_ = ({ stream }) => ({
  source: stream,
  target: stream
});
var _void_ = () => void 0;

// src/projection-builder.ts
function isProjection(x) {
  return x != null && x._tag === "Projection";
}
function projection(target, events = {}) {
  const defaultResolver = target ? { target } : void 0;
  const builder = {
    on: (entry) => {
      const keys = Object.keys(entry);
      if (keys.length !== 1) throw new Error(".on() requires exactly one key");
      const event = keys[0];
      const schema = entry[event];
      if (!(event in events)) {
        events[event] = {
          schema,
          reactions: /* @__PURE__ */ new Map()
        };
      }
      return {
        do: (handler) => {
          const reaction = {
            handler,
            resolver: defaultResolver ?? _this_,
            options: {
              blockOnError: true,
              maxRetries: 3
            }
          };
          const register = events[event];
          const name = handler.name || `${event}_${register.reactions.size}`;
          register.reactions.set(name, reaction);
          const nextBuilder = projection(
            target,
            events
          );
          return {
            ...nextBuilder,
            to(resolver) {
              register.reactions.set(name, {
                ...reaction,
                resolver: typeof resolver === "string" ? { target: resolver } : resolver
              });
              return nextBuilder;
            },
            void() {
              register.reactions.set(name, {
                ...reaction,
                resolver: _void_
              });
              return nextBuilder;
            }
          };
        }
      };
    },
    build: () => ({
      _tag: "Projection",
      events
    }),
    events
  };
  return builder;
}

// src/slice-builder.ts
function isSlice(x) {
  return x != null && x._tag === "Slice";
}
function slice(states = /* @__PURE__ */ new Map(), actions = {}, events = {}) {
  const builder = {
    with: (state2) => {
      registerState(state2, states, actions, events);
      return slice(states, actions, events);
    },
    on: (event) => ({
      do: (handler, options) => {
        const reaction = {
          handler,
          resolver: _this_,
          options: {
            blockOnError: options?.blockOnError ?? true,
            maxRetries: options?.maxRetries ?? 3
          }
        };
        const name = handler.name || `${String(event)}_${events[event].reactions.size}`;
        events[event].reactions.set(name, reaction);
        return {
          ...builder,
          to(resolver) {
            events[event].reactions.set(name, {
              ...reaction,
              resolver: typeof resolver === "string" ? { target: resolver } : resolver
            });
            return builder;
          },
          void() {
            events[event].reactions.set(name, {
              ...reaction,
              resolver: _void_
            });
            return builder;
          }
        };
      }
    }),
    build: () => ({
      _tag: "Slice",
      states,
      events
    }),
    events
  };
  return builder;
}

// src/act-builder.ts
function act(states = /* @__PURE__ */ new Map(), registry = {
  actions: {},
  events: {}
}) {
  const builder = {
    with: ((input) => {
      if (isProjection(input)) {
        for (const eventName of Object.keys(input.events)) {
          const projRegister = input.events[eventName];
          const existing = registry.events[eventName];
          if (!existing) {
            registry.events[eventName] = {
              schema: projRegister.schema,
              reactions: new Map(projRegister.reactions)
            };
          } else {
            for (const [name, reaction] of projRegister.reactions) {
              let key = name;
              while (existing.reactions.has(key)) key = `${key}_p`;
              existing.reactions.set(key, reaction);
            }
          }
        }
        return act(states, registry);
      }
      if (isSlice(input)) {
        for (const s of input.states.values()) {
          registerState(s, states, registry.actions, registry.events);
        }
        for (const eventName of Object.keys(input.events)) {
          const sliceRegister = input.events[eventName];
          for (const [name, reaction] of sliceRegister.reactions) {
            registry.events[eventName].reactions.set(name, reaction);
          }
        }
        return act(states, registry);
      }
      registerState(input, states, registry.actions, registry.events);
      return act(states, registry);
    }),
    /**
     * Adds a reaction to an event.
     *
     * @template K The type of event
     * @param event The event to add a reaction to
     * @returns The builder
     */
    on: (event) => ({
      do: (handler, options) => {
        const reaction = {
          handler,
          resolver: _this_,
          options: {
            blockOnError: options?.blockOnError ?? true,
            maxRetries: options?.maxRetries ?? 3
          }
        };
        const name = handler.name || `${String(event)}_${registry.events[event].reactions.size}`;
        registry.events[event].reactions.set(name, reaction);
        return {
          ...builder,
          to(resolver) {
            registry.events[event].reactions.set(name, {
              ...reaction,
              resolver: typeof resolver === "string" ? { target: resolver } : resolver
            });
            return builder;
          },
          void() {
            registry.events[event].reactions.set(name, {
              ...reaction,
              resolver: _void_
            });
            return builder;
          }
        };
      }
    }),
    build: () => new Act(registry, states),
    events: registry.events
  };
  return builder;
}

// src/state-builder.ts
function state(entry) {
  const keys = Object.keys(entry);
  if (keys.length !== 1) throw new Error("state() requires exactly one key");
  const name = keys[0];
  const stateSchema = entry[name];
  return {
    init(init) {
      return {
        emits(events) {
          return {
            patch(patch2) {
              return action_builder({
                events,
                actions: {},
                state: stateSchema,
                name,
                init,
                patch: patch2,
                on: {}
              });
            }
          };
        }
      };
    }
  };
}
function action_builder(state2) {
  return {
    on(entry) {
      const keys = Object.keys(entry);
      if (keys.length !== 1) throw new Error(".on() requires exactly one key");
      const action2 = keys[0];
      const schema = entry[action2];
      if (action2 in state2.actions)
        throw new Error(`Duplicate action "${action2}"`);
      const actions = { ...state2.actions, [action2]: schema };
      const on = { ...state2.on };
      const _given = { ...state2.given };
      function given(rules) {
        _given[action2] = rules;
        return { emit };
      }
      function emit(handler) {
        on[action2] = handler;
        return action_builder({
          ...state2,
          actions,
          on,
          given: _given
        });
      }
      return { given, emit };
    },
    snap(snap2) {
      return action_builder({ ...state2, snap: snap2 });
    },
    build() {
      return state2;
    }
  };
}
export {
  Act,
  ActorSchema,
  CausationEventSchema,
  CommittedMetaSchema,
  ConcurrencyError,
  Environments,
  Errors,
  EventMetaSchema,
  ExitCodes,
  InvariantError,
  LogLevels,
  PackageSchema,
  QuerySchema,
  SNAP_EVENT,
  TargetSchema,
  ValidationError,
  ZodEmpty,
  act,
  build_tracer,
  config,
  dispose,
  disposeAndExit,
  extend,
  isProjection,
  isSlice,
  logger,
  patch,
  port,
  projection,
  sleep,
  slice,
  state,
  store,
  validate
};
//# sourceMappingURL=index.js.map